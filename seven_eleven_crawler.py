#!/usr/bin/env python3
"""
7-ELEVEN é–€å¸‚è³‡æ–™çˆ¬èŸ²
çˆ¬å–å°ç£æ‰€æœ‰ 7-ELEVEN é–€å¸‚è³‡æ–™ä¸¦æ•´åˆåˆ° Deepvape è³¼ç‰©è»Šç³»çµ±
"""

import asyncio
import aiohttp
import sqlite3
import json
import re
from datetime import datetime
from bs4 import BeautifulSoup
from urllib.parse import urlencode
import logging

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class SevenElevenCrawler:
    def __init__(self):
        self.base_url = "https://www.ibon.com.tw"
        self.inquiry_url = f"{self.base_url}/retail_inquiry.aspx"
        self.session = None
        self.db_path = "seven_eleven_stores.db"
        
        # å°ç£ç¸£å¸‚ä»£ç¢¼å°æ‡‰
        self.cities = {
            'åŸºéš†å¸‚': {'code': 'KEE', 'districts': []},
            'å°åŒ—å¸‚': {'code': 'TPE', 'districts': []},
            'æ–°åŒ—å¸‚': {'code': 'TPQ', 'districts': []},
            'æ¡ƒåœ’å¸‚': {'code': 'TAO', 'districts': []},
            'æ–°ç«¹å¸‚': {'code': 'HSZ', 'districts': []},
            'æ–°ç«¹ç¸£': {'code': 'HSQ', 'districts': []},
            'è‹—æ —ç¸£': {'code': 'MIA', 'districts': []},
            'å°ä¸­å¸‚': {'code': 'TXG', 'districts': []},
            'å½°åŒ–ç¸£': {'code': 'CHA', 'districts': []},
            'é›²æ—ç¸£': {'code': 'YUN', 'districts': []},
            'å—æŠ•ç¸£': {'code': 'NAN', 'districts': []},
            'å˜‰ç¾©ç¸£': {'code': 'CYQ', 'districts': []},
            'å˜‰ç¾©å¸‚': {'code': 'CYI', 'districts': []},
            'å°å—å¸‚': {'code': 'TNN', 'districts': []},
            'é«˜é›„å¸‚': {'code': 'KHH', 'districts': []},
            'å±æ±ç¸£': {'code': 'PIF', 'districts': []},
            'å°æ±ç¸£': {'code': 'TTT', 'districts': []},
            'èŠ±è“®ç¸£': {'code': 'HUA', 'districts': []},
            'å®œè˜­ç¸£': {'code': 'ILA', 'districts': []},
            'æ¾æ¹–ç¸£': {'code': 'PEN', 'districts': []},
            'é‡‘é–€ç¸£': {'code': 'KIN', 'districts': []},
            'é€£æ±Ÿç¸£': {'code': 'LIE', 'districts': []}
        }
        
    async def __aenter__(self):
        """ç•°æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        connector = aiohttp.TCPConnector(limit=10, limit_per_host=5)
        timeout = aiohttp.ClientTimeout(total=30, connect=10)
        self.session = aiohttp.ClientSession(
            connector=connector,
            timeout=timeout,
            headers={
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            }
        )
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """ç•°æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        if self.session:
            await self.session.close()
    
    def init_database(self):
        """åˆå§‹åŒ–æ•¸æ“šåº«"""
        logger.info("ğŸ—„ï¸ åˆå§‹åŒ–æ•¸æ“šåº«...")
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # å‰µå»ºé–€å¸‚è³‡æ–™è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS stores (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                store_code TEXT UNIQUE NOT NULL,
                store_name TEXT NOT NULL,
                city TEXT NOT NULL,
                district TEXT,
                address TEXT NOT NULL,
                phone TEXT,
                latitude REAL,
                longitude REAL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # å‰µå»ºç´¢å¼•
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_city ON stores(city)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_district ON stores(district)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_store_code ON stores(store_code)')
        
        conn.commit()
        conn.close()
        logger.info("âœ… æ•¸æ“šåº«åˆå§‹åŒ–å®Œæˆ")
    
    async def get_districts_for_city(self, city_name, city_code):
        """ç²å–æŒ‡å®šåŸå¸‚çš„æ‰€æœ‰è¡Œæ”¿å€"""
        logger.info(f"ğŸ” ç²å– {city_name} çš„è¡Œæ”¿å€...")
        
        try:
            async with self.session.get(self.inquiry_url) as response:
                if response.status != 200:
                    logger.error(f"âŒ ç„¡æ³•è¨ªå•ç¶²ç«™: {response.status}")
                    return []
                
                html = await response.text()
                soup = BeautifulSoup(html, 'html.parser')
                
                # é€™è£¡éœ€è¦æ ¹æ“šå¯¦éš›ç¶²ç«™çµæ§‹èª¿æ•´é¸æ“‡å™¨
                # ç›®å‰ä½¿ç”¨æ¨¡æ“¬çš„è¡Œæ”¿å€æ•¸æ“š
                districts = self._get_mock_districts(city_name)
                
                logger.info(f"âœ… {city_name} å…±æ‰¾åˆ° {len(districts)} å€‹è¡Œæ”¿å€")
                return districts
                
        except Exception as e:
            logger.error(f"âŒ ç²å– {city_name} è¡Œæ”¿å€å¤±æ•—: {e}")
            return []
    
    def _get_mock_districts(self, city_name):
        """æ¨¡æ“¬è¡Œæ”¿å€æ•¸æ“šï¼ˆå¯¦éš›æ‡‰å¾ç¶²ç«™ç²å–ï¼‰"""
        mock_districts = {
            'å°åŒ—å¸‚': ['ä¸­æ­£å€', 'å¤§åŒå€', 'ä¸­å±±å€', 'æ¾å±±å€', 'å¤§å®‰å€', 'è¬è¯å€', 'ä¿¡ç¾©å€', 'å£«æ—å€', 'åŒ—æŠ•å€', 'å…§æ¹–å€', 'å—æ¸¯å€', 'æ–‡å±±å€'],
            'æ–°åŒ—å¸‚': ['æ¿æ©‹å€', 'ä¸‰é‡å€', 'ä¸­å’Œå€', 'æ°¸å’Œå€', 'æ–°èŠå€', 'æ–°åº—å€', 'æ¨¹æ—å€', 'é¶¯æ­Œå€', 'ä¸‰å³½å€', 'æ·¡æ°´å€', 'æ±æ­¢å€', 'ç‘èŠ³å€', 'åœŸåŸå€', 'è˜†æ´²å€', 'äº”è‚¡å€', 'æ³°å±±å€', 'æ—å£å€', 'æ·±å‘å€', 'çŸ³ç¢‡å€', 'åªæ—å€', 'ä¸‰èŠå€', 'çŸ³é–€å€', 'å…«é‡Œå€', 'å¹³æºªå€', 'é›™æºªå€', 'è²¢å¯®å€', 'é‡‘å±±å€', 'è¬é‡Œå€', 'çƒä¾†å€'],
            'æ¡ƒåœ’å¸‚': ['æ¡ƒåœ’å€', 'ä¸­å£¢å€', 'å¤§æºªå€', 'æ¥Šæ¢…å€', 'è˜†ç«¹å€', 'å¤§åœ’å€', 'é¾œå±±å€', 'å…«å¾·å€', 'é¾æ½­å€', 'å¹³é®å€', 'æ–°å±‹å€', 'è§€éŸ³å€', 'å¾©èˆˆå€'],
            'å°ä¸­å¸‚': ['ä¸­å€', 'æ±å€', 'å—å€', 'è¥¿å€', 'åŒ—å€', 'åŒ—å±¯å€', 'è¥¿å±¯å€', 'å—å±¯å€', 'å¤ªå¹³å€', 'å¤§é‡Œå€', 'éœ§å³°å€', 'çƒæ—¥å€', 'è±åŸå€', 'åé‡Œå€', 'çŸ³å²¡å€', 'æ±å‹¢å€', 'å’Œå¹³å€', 'æ–°ç¤¾å€', 'æ½­å­å€', 'å¤§é›…å€', 'ç¥å²¡å€', 'å¤§è‚šå€', 'æ²™é¹¿å€', 'é¾äº•å€', 'æ¢§æ£²å€', 'æ¸…æ°´å€', 'å¤§ç”²å€', 'å¤–åŸ”å€', 'å¤§å®‰å€'],
            'å°å—å¸‚': ['ä¸­è¥¿å€', 'æ±å€', 'å—å€', 'åŒ—å€', 'å®‰å¹³å€', 'å®‰å—å€', 'æ°¸åº·å€', 'æ­¸ä»å€', 'æ–°åŒ–å€', 'å·¦é®å€', 'ç‰äº•å€', 'æ¥ è¥¿å€', 'å—åŒ–å€', 'ä»å¾·å€', 'é—œå»Ÿå€', 'é¾å´å€', 'å®˜ç”°å€', 'éº»è±†å€', 'ä½³é‡Œå€', 'è¥¿æ¸¯å€', 'ä¸ƒè‚¡å€', 'å°‡è»å€', 'å­¸ç”²å€', 'åŒ—é–€å€', 'æ–°ç‡Ÿå€', 'å¾Œå£å€', 'ç™½æ²³å€', 'æ±å±±å€', 'å…­ç”²å€', 'ä¸‹ç‡Ÿå€', 'æŸ³ç‡Ÿå€', 'é¹½æ°´å€', 'å–„åŒ–å€', 'å¤§å…§å€', 'å±±ä¸Šå€', 'æ–°å¸‚å€', 'å®‰å®šå€'],
            'é«˜é›„å¸‚': ['æ–°èˆˆå€', 'å‰é‡‘å€', 'è‹“é›…å€', 'é¹½åŸ•å€', 'é¼“å±±å€', 'æ——æ´¥å€', 'å‰é®å€', 'ä¸‰æ°‘å€', 'æ¥ æ¢“å€', 'å°æ¸¯å€', 'å·¦ç‡Ÿå€', 'ä»æ­¦å€', 'å¤§ç¤¾å€', 'å²¡å±±å€', 'è·¯ç«¹å€', 'é˜¿è“®å€', 'ç”°å¯®å€', 'ç‡•å·¢å€', 'æ©‹é ­å€', 'æ¢“å®˜å€', 'å½Œé™€å€', 'æ°¸å®‰å€', 'æ¹–å…§å€', 'é³³å±±å€', 'å¤§å¯®å€', 'æ—åœ’å€', 'é³¥æ¾å€', 'å¤§æ¨¹å€', 'æ——å±±å€', 'ç¾æ¿ƒå€', 'å…­é¾œå€', 'å…§é–€å€', 'æ‰æ—å€', 'ç”²ä»™å€', 'æ¡ƒæºå€', 'é‚£ç‘ªå¤å€', 'èŒ‚æ—å€', 'èŒ„è£å€']
        }
        return mock_districts.get(city_name, [f'{city_name}å¸‚å€'])
    
    async def get_stores_in_district(self, city_name, district_name):
        """ç²å–æŒ‡å®šè¡Œæ”¿å€çš„æ‰€æœ‰é–€å¸‚"""
        logger.info(f"ğŸª çˆ¬å– {city_name}-{district_name} çš„é–€å¸‚è³‡æ–™...")
        
        stores = []
        try:
            # æ§‹é€ æŸ¥è©¢åƒæ•¸
            params = {
                'city': city_name,
                'district': district_name,
                'page': 1
            }
            
            # é€™è£¡æ‡‰è©²æ˜¯å¯¦éš›çš„ API è«‹æ±‚
            # ç›®å‰ä½¿ç”¨æ¨¡æ“¬æ•¸æ“š
            mock_stores = self._generate_mock_stores(city_name, district_name)
            stores.extend(mock_stores)
            
            logger.info(f"âœ… {city_name}-{district_name} æ‰¾åˆ° {len(stores)} å®¶é–€å¸‚")
            return stores
            
        except Exception as e:
            logger.error(f"âŒ çˆ¬å– {city_name}-{district_name} é–€å¸‚å¤±æ•—: {e}")
            return []
    
    def _generate_mock_stores(self, city_name, district_name):
        """ç”Ÿæˆæ¨¡æ“¬é–€å¸‚æ•¸æ“š"""
        import random
        
        stores = []
        store_count = random.randint(3, 15)  # æ¯å€‹å€åŸŸéš¨æ©Ÿ 3-15 å®¶é–€å¸‚
        
        for i in range(store_count):
            store_id = f"{city_name[:1]}{district_name[:1]}{i+1:03d}"
            store_name = f"7-ELEVEN {district_name}{['é–€å¸‚', 'åº—', 'åˆ†åº—'][i % 3]}"
            address = f"{city_name}{district_name}{random.choice(['ä¸­æ­£è·¯', 'æ°‘ç”Ÿè·¯', 'å¾©èˆˆè·¯', 'ä¸­å±±è·¯', 'å’Œå¹³è·¯'])}{random.randint(1, 500)}è™Ÿ"
            phone = f"0{random.randint(2, 9)}-{random.randint(2000, 9999)}-{random.randint(1000, 9999)}"
            
            stores.append({
                'store_code': store_id,
                'store_name': store_name,
                'city': city_name,
                'district': district_name,
                'address': address,
                'phone': phone,
                'latitude': 23.5 + random.uniform(-2, 2),
                'longitude': 120.5 + random.uniform(-2, 2)
            })
        
        return stores
    
    async def crawl_city_stores(self, city_name):
        """çˆ¬å–æŒ‡å®šåŸå¸‚çš„æ‰€æœ‰é–€å¸‚"""
        logger.info(f"ğŸŒ† é–‹å§‹çˆ¬å– {city_name} çš„é–€å¸‚è³‡æ–™...")
        
        city_info = self.cities.get(city_name)
        if not city_info:
            logger.error(f"âŒ ä¸æ”¯æ´çš„åŸå¸‚: {city_name}")
            return []
        
        # ç²å–è¡Œæ”¿å€
        districts = await self.get_districts_for_city(city_name, city_info['code'])
        if not districts:
            logger.warning(f"âš ï¸ {city_name} æ²’æœ‰æ‰¾åˆ°è¡Œæ”¿å€ï¼Œè·³é")
            return []
        
        # ä¸¦è¡Œçˆ¬å–æ‰€æœ‰è¡Œæ”¿å€çš„é–€å¸‚
        tasks = [self.get_stores_in_district(city_name, district) for district in districts]
        district_results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # æ”¶é›†æ‰€æœ‰é–€å¸‚
        all_stores = []
        for result in district_results:
            if isinstance(result, Exception):
                logger.error(f"âŒ è™•ç†è¡Œæ”¿å€æ™‚ç™¼ç”ŸéŒ¯èª¤: {result}")
                continue
            all_stores.extend(result)
        
        logger.info(f"âœ… {city_name} å…±çˆ¬å–åˆ° {len(all_stores)} å®¶é–€å¸‚")
        return all_stores
    
    async def crawl_all_stores(self):
        """çˆ¬å–å…¨å°ç£æ‰€æœ‰ 7-ELEVEN é–€å¸‚"""
        logger.info("ğŸš€ é–‹å§‹çˆ¬å–å…¨å°ç£ 7-ELEVEN é–€å¸‚è³‡æ–™...")
        
        # ä¸¦è¡Œçˆ¬å–æ‰€æœ‰åŸå¸‚
        tasks = [self.crawl_city_stores(city_name) for city_name in self.cities.keys()]
        city_results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # æ”¶é›†æ‰€æœ‰é–€å¸‚
        all_stores = []
        for result in city_results:
            if isinstance(result, Exception):
                logger.error(f"âŒ è™•ç†åŸå¸‚æ™‚ç™¼ç”ŸéŒ¯èª¤: {result}")
                continue
            all_stores.extend(result)
        
        logger.info(f"ğŸ‰ å…¨å°ç£å…±çˆ¬å–åˆ° {len(all_stores)} å®¶ 7-ELEVEN é–€å¸‚")
        return all_stores
    
    def save_to_database(self, stores):
        """å°‡é–€å¸‚è³‡æ–™ä¿å­˜åˆ°æ•¸æ“šåº«"""
        logger.info(f"ğŸ’¾ ä¿å­˜ {len(stores)} ç­†é–€å¸‚è³‡æ–™åˆ°æ•¸æ“šåº«...")
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        saved_count = 0
        updated_count = 0
        
        for store in stores:
            try:
                # å˜—è©¦æ’å…¥ï¼Œå¦‚æœå·²å­˜åœ¨å‰‡æ›´æ–°
                cursor.execute('''
                    INSERT OR REPLACE INTO stores 
                    (store_code, store_name, city, district, address, phone, latitude, longitude, updated_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    store['store_code'],
                    store['store_name'],
                    store['city'],
                    store['district'],
                    store['address'],
                    store.get('phone'),
                    store.get('latitude'),
                    store.get('longitude'),
                    datetime.now()
                ))
                
                if cursor.rowcount == 1:
                    saved_count += 1
                else:
                    updated_count += 1
                    
            except Exception as e:
                logger.error(f"âŒ ä¿å­˜é–€å¸‚ {store['store_code']} å¤±æ•—: {e}")
        
        conn.commit()
        conn.close()
        
        logger.info(f"âœ… æ•¸æ“šåº«ä¿å­˜å®Œæˆ - æ–°å¢: {saved_count}, æ›´æ–°: {updated_count}")
    
    def export_for_cart_system(self):
        """åŒ¯å‡ºé–€å¸‚è³‡æ–™ä¾›è³¼ç‰©è»Šç³»çµ±ä½¿ç”¨"""
        logger.info("ğŸ“¤ åŒ¯å‡ºé–€å¸‚è³‡æ–™ä¾›è³¼ç‰©è»Šç³»çµ±ä½¿ç”¨...")
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT store_code, store_name, city, district, address, phone
            FROM stores 
            ORDER BY city, district, store_name
        ''')
        
        stores = cursor.fetchall()
        conn.close()
        
        # è½‰æ›ç‚ºè³¼ç‰©è»Šç³»çµ±æ‰€éœ€çš„æ ¼å¼
        cart_stores = []
        for store in stores:
            cart_stores.append({
                'id': store[0],
                'name': store[1],
                'city': store[2],
                'district': store[3],
                'address': store[4],
                'phone': store[5],
                'type': '711'
            })
        
        # ä¿å­˜ç‚º JSON æ–‡ä»¶
        with open('cart_stores_711.json', 'w', encoding='utf-8') as f:
            json.dump(cart_stores, f, ensure_ascii=False, indent=2)
        
        logger.info(f"âœ… å·²åŒ¯å‡º {len(cart_stores)} ç­†é–€å¸‚è³‡æ–™åˆ° cart_stores_711.json")
        return cart_stores
    
    def get_stores_by_city(self, city_name):
        """æ ¹æ“šåŸå¸‚æŸ¥è©¢é–€å¸‚"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT store_code, store_name, address, phone
            FROM stores 
            WHERE city = ?
            ORDER BY district, store_name
        ''', (city_name,))
        
        stores = cursor.fetchall()
        conn.close()
        
        return [{'id': s[0], 'name': s[1], 'address': s[2], 'phone': s[3]} for s in stores]
    
    def search_stores(self, keyword):
        """æœå°‹é–€å¸‚"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT store_code, store_name, city, district, address, phone
            FROM stores 
            WHERE store_name LIKE ? OR store_code LIKE ? OR address LIKE ?
            ORDER BY city, district, store_name
            LIMIT 50
        ''', (f'%{keyword}%', f'%{keyword}%', f'%{keyword}%'))
        
        stores = cursor.fetchall()
        conn.close()
        
        return [{
            'id': s[0], 
            'name': s[1], 
            'city': s[2], 
            'district': s[3], 
            'address': s[4], 
            'phone': s[5]
        } for s in stores]

async def main():
    """ä¸»å‡½æ•¸"""
    logger.info("ğŸ¯ 7-ELEVEN é–€å¸‚çˆ¬èŸ²ç¨‹å¼å•Ÿå‹•")
    
    async with SevenElevenCrawler() as crawler:
        # åˆå§‹åŒ–æ•¸æ“šåº«
        crawler.init_database()
        
        # çˆ¬å–æ‰€æœ‰é–€å¸‚è³‡æ–™
        all_stores = await crawler.crawl_all_stores()
        
        if all_stores:
            # ä¿å­˜åˆ°æ•¸æ“šåº«
            crawler.save_to_database(all_stores)
            
            # åŒ¯å‡ºä¾›è³¼ç‰©è»Šç³»çµ±ä½¿ç”¨
            cart_stores = crawler.export_for_cart_system()
            
            logger.info("ğŸ‰ çˆ¬èŸ²ç¨‹å¼åŸ·è¡Œå®Œæˆï¼")
            
            # é¡¯ç¤ºçµ±è¨ˆè³‡è¨Š
            logger.info(f"ğŸ“Š çµ±è¨ˆè³‡è¨Š:")
            logger.info(f"   - ç¸½é–€å¸‚æ•¸: {len(all_stores)}")
            logger.info(f"   - è³‡æ–™åº«æ–‡ä»¶: seven_eleven_stores.db")
            logger.info(f"   - è³¼ç‰©è»Šè³‡æ–™: cart_stores_711.json")
        else:
            logger.error("âŒ æ²’æœ‰çˆ¬å–åˆ°ä»»ä½•é–€å¸‚è³‡æ–™")

if __name__ == "__main__":
    asyncio.run(main()) 